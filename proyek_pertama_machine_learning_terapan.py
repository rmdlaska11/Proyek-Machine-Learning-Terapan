# -*- coding: utf-8 -*-
"""Proyek Pertama Machine Learning Terapan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gEdZygJmxteUCdpW0je9U4bpjTYzNmti

<h1> <b>Prediksi Penyakit Diabetes<b> <h1>

# Import Library

Mengimport library yang akan digunakan
"""

# Commented out IPython magic to ensure Python compatibility.
# import library
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

"""# Data Loading

Mengunduh data dari sumber https://www.kaggle.com/datasets/whenamancodes/predict-diabities/data dan diubah ke dalam bentuk dataframe

Kolom atau variabel yang ada pada dataset:

* Pregnancies   : menyatakan jumlah kehamilan
* Glucose       : menyatakan kadar Glukosa dalam darah
* BloodPressure : menyatakan pengukuran tekanan darah
* SkinThickness :	menyatakan ketebalan kulit
* Insulin       :	menyatakan kadar Insulin dalam darah
* BMI 	        : menyatakan indeks massa tubuh
* DiabetesPedigreeFunction : menyatakan persentase Diabetes
* Age                      : menyatakan usia
* Outcome : menyatakan hasil akhir 1 adalah Ya dan 0 adalah Tidak
"""

# Menghubungkan Colab ke Drive
from google.colab import drive
drive.mount('/content/drive')

data = pd.read_csv('/content/drive/MyDrive/Dataset/diabetes.csv')
data

"""Output kode diatas memberikan informasi sebagai berikut:

*   Terdapat 768 baris dalam dataset
*   Ada 9 Kolom yaitu: Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age, dan Outcome.

# Explanatory Data Analysis

Melakukan beberapa tahapan sebagai berikut :

1.   Deskripsi Variabel
2.   Menangani missing value dan outliers
3.   Analisis Univariate

<h2> Deskripsi Variabel <h2>
"""

data.info()

"""Dari output terlihat bahwa:

* Terdapat 2 kolom numerik dengan tipe data float64 yaitu: BMI dan DiabetesPedigreeFunction.
* Terdapat 7 kolom numerik dengan tipe data int64, yaitu: Pregnancies,Glucose, BloodPressure, SkinThickness, Insulin, Age , dan Outcome.
"""

data.describe()

"""<h2> Menangani missing value <h2>

Melakukan pengecekan terlebih dahulu apakah didalam dataset terdapat missing value dengan kode berikut :
"""

# Mengecek apakah ada data duplikat
data.duplicated().sum()

data.isnull().sum()

"""Berdasarkan output diatas dataset yang digunakan tidak memiliki missing value

<h2> Menangani Outliers <h2>

outliers adalah sampel yang nilainya sangat jauh dari cakupan umum data utama. Pada kasus ini, outliers akan dideteksi dengan teknik visualisasi data (boxplot). Kemudian, ouliers akan ditangani dengan teknik IQR method
"""

# Membuat boxplot untuk semua kolom
sns.set(style="whitegrid")
plt.figure(figsize=(10, 6))

# Fungsi boxplot dari Seaborn
sns.boxplot(data=data)

# Menambahkan judul
plt.title('Boxplot untuk Semua Kolom')

# Menampilkan boxplot
plt.show()

Q1 = data.quantile(0.25)
Q3 = data.quantile(0.75)
IQR = Q3 - Q1
data = data[~((data<(Q1-1.5*IQR))|(data>(Q3+1.5*IQR))).any(axis=1)]

# Cek ukuran dataset setelah kita drop outliers
data.shape

"""<h2> EDA - Analisis Univariate <h2>

Analisis univariate merupakan proses untuk mengeksplorasi dan menjelaskan setiap variabel dalam kumpulan data secara terpisah.

<h4> Analisis fitur numerik <h4>
"""

data.hist(bins=50, figsize=(20,15))
plt.show()

data.groupby('Outcome').size()

"""Berdasarkan output di atas, jumlah orang yang memiliki penyakit diabetes berjumlah 200, sedangkan yang tidak terkena sebanyak 439 orang.

#Data Preparation

<h4> Imbalance Dataset <h4>

Karena data outcome yang dimiliki tidak seimbang maka kita perlu menyeimbangkan datanya terllebih dahulu
"""

X = data.drop(columns = 'Outcome')
y = data['Outcome']
print(X)
print(y)

from imblearn.over_sampling import RandomOverSampler
sm = RandomOverSampler(random_state=42)
X_sampling, y_sampling = sm.fit_resample(X,y)

import seaborn as sns
import matplotlib.pyplot as plt
fig = plt.subplots(figsize=(9,6))
sns.histplot(data=y_sampling)
plt.show()

"""Berdasarkan output diatas variabel outcome telah seimbang dengan jumlah masing-masing 439.

<h4> Train-Test Split <h4>

 Menggunakan proporsi pembagian sebesar 80:20 dengan fungsi train_test_split dari sklearn.
"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_sampling, y_sampling, test_size=0.2, random_state=42)

print(f'Total # of sample in whole dataset: {len(X_sampling)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""<h4> Standarisasi <h4>

Standarisasi menggunakan teknik StandarScaler dari library Scikitlearn,

StandardScaler melakukan proses standarisasi fitur dengan mengurangkan mean (nilai rata-rata) kemudian membaginya dengan standar deviasi untuk menggeser distribusi.  StandardScaler menghasilkan distribusi dengan standar deviasi sama dengan 1 dan mean sama dengan 0.
"""

from sklearn.preprocessing import StandardScaler

Scaler = StandardScaler()
X_train = Scaler.fit_transform(X_train)
X_test = Scaler.transform(X_test)

"""#Model Development

Model development adalah tahapan di mana kita menggunakan algoritma machine learning untuk menjawab problem statement dari tahap business understanding.
"""

from sklearn import svm
from sklearn.metrics import accuracy_score

svm = svm.SVC()
svm.fit(X_train, y_train)
y_pred = svm.predict(X_test)

"""#Evaluasi Model"""

from sklearn.metrics import classification_report, confusion_matrix
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))

"""#Tuning Hyperparameter"""

from sklearn.model_selection import GridSearchCV
from sklearn import svm

# Definisikan model SVM dengan kernel radial
svm_rbf = svm.SVC(kernel='rbf')

# Set parameter yang akan di-tune
param_grid = {'C': [0.1, 1, 10, 100],
              'gamma': [0.01, 0.1, 1, 10]}

# Buat objek GridSearchCV
grid_search = GridSearchCV(svm_rbf, param_grid, cv=5, scoring='accuracy')

# Lakukan penelusuran parameter pada data training
grid_search.fit(X_train, y_train)

# Cetak parameter terbaik yang ditemukan
best_params = grid_search.best_params_
print(f"Parameter Terbaik: {best_params}")

# Prediksi dengan model terbaik
y_pred = grid_search.predict(X_test)

# Evaluasi performa model
accuracy = accuracy_score(y_test, y_pred)
print(f"Akurasi Model: {accuracy:.2f}")# Definisikan model SVM dengan kernel radial

from sklearn.metrics import classification_report, confusion_matrix
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))